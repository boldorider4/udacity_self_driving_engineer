{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import car and non-car images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.utils import shuffle as Shuffle\n",
    "%matplotlib inline \n",
    "\n",
    "# Read in cars and notcars\n",
    "cars = []\n",
    "images = glob.glob('vehicles/*/*.png')\n",
    "for image in images:\n",
    "    cars.append(image)\n",
    "Shuffle(cars)\n",
    "\n",
    "notcars = []\n",
    "images = glob.glob('non-vehicles/*/*.png')\n",
    "for image in images:\n",
    "    notcars.append(image)\n",
    "Shuffle(notcars)\n",
    "\n",
    "udacity_cars = []\n",
    "with open('./object-detection-crowdai/labels.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if 'Car' in line[5]:\n",
    "            car_dict = { \"file\": line[4], \"bbox\": ((int(line[0]),int(line[1])), (int(line[2]),int(line[3]))) }\n",
    "            udacity_cars.append(car_dict)\n",
    "Shuffle(udacity_cars)\n",
    "\n",
    "# Saving classifier to pickle file\n",
    "pickle_carpics = { \"cars\" : cars, \"notcars\" : notcars, \"udacity_cars\" : udacity_cars }\n",
    "with open('carpics.p', 'wb') as pf:\n",
    "    pickle.dump(pickle_carpics, pf)\n",
    "    print('pickle file saved successfully!')\n",
    "    pf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display example car and non-car images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rand_car = np.random.randint(0, len(cars))\n",
    "rand_notcar = np.random.randint(0, len(notcars))\n",
    "rand_udacity_car = np.random.randint(0, len(udacity_cars))\n",
    "\n",
    "rand_car = mpimg.imread(cars[rand_car])\n",
    "rand_notcar = mpimg.imread(notcars[rand_notcar])\n",
    "filename = os.path.join('.', 'object-detection-crowdai', udacity_cars[rand_udacity_car][\"file\"])\n",
    "rand_udacity_car_image = mpimg.imread(filename)\n",
    "\n",
    "bbox = udacity_cars[rand_udacity_car][\"bbox\"]\n",
    "rand_udacity_car_image = rand_udacity_car_image[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(rand_car)\n",
    "plt.figure()\n",
    "plt.imshow(rand_notcar)\n",
    "plt.figure()\n",
    "plt.imshow(rand_udacity_car_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define image processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "\n",
    "def convert_color(img, conv='RGB'):\n",
    "    if conv == 'YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    elif conv == 'LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    elif conv == 'HLS':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    elif conv == 'HSV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    elif conv == 'YUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    elif conv is not 'RGB':\n",
    "        print('Invalid color space')\n",
    "    return img\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "def color_hist(img, nbins=32):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define feature extraction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "def extract_features(imgs, w_bboxes=False, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        if w_bboxes:\n",
    "            \n",
    "            bbox = file[\"bbox\"]\n",
    "            min_bbox_size = min( bbox[1][1]-bbox[0][1], bbox[1][0]-bbox[0][0] )\n",
    "            max_bbox_size = max( bbox[1][1]-bbox[0][1], bbox[1][0]-bbox[0][0] )\n",
    "            \n",
    "            # check if bounding boxes indeces are ok\n",
    "            if min_bbox_size is 0 or max_bbox_size is 0:\n",
    "                continue\n",
    "            # calculate bounding box aspect ratio\n",
    "            bbox_aratio = max_bbox_size / min_bbox_size\n",
    "            # if aspect ratio is not adequate or if bounding box is too small, skip image\n",
    "            if min_bbox_size >= 64 and bbox_aratio < 2.5:\n",
    "                image = mpimg.imread(os.path.join('.', 'object-detection-crowdai', file[\"file\"]))\n",
    "                image = image[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]]\n",
    "                # if bounding box is too far from square shape, crop square shape out of it\n",
    "                if bbox_aratio > 1.2:\n",
    "                    image = image[0:min_bbox_size, 0:min_bbox_size]\n",
    "                \n",
    "                # resize image to standard 64-by-64 image\n",
    "                image_0 = cv2.resize(image[:,:,0], (64,64))\n",
    "                image_1 = cv2.resize(image[:,:,1], (64,64))\n",
    "                image_2 = cv2.resize(image[:,:,2], (64,64))\n",
    "                image = np.dstack((image_0, image_1, image_2))\n",
    "            else:\n",
    "                continue\n",
    "        else:  \n",
    "            image = mpimg.imread(file)\n",
    "        \n",
    "        # scaling to [0, 1] range in case range was initially [0, 255] to enforce consistency\n",
    "        if (np.max(image) > 1.0):\n",
    "            image = image.astype(np.float32)/255\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "            \n",
    "        # apply color conversion if other than 'RGB'\n",
    "        feature_image = convert_color(np.copy(image), conv=color_space)\n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train a classifier with car and non-car images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_space = 'LUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 8  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "extract_spatial_features = True # Spatial features on or off\n",
    "extract_hist_bins_features = True # Histogram features on or off\n",
    "extract_hog_features = True # HOG features on or off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Restore previously saved classifier and scaler\n",
    "if os.path.isfile('carpics.p'):\n",
    "    with open('carpics.p', 'rb') as pf:\n",
    "        pickle_carpics = pickle.load(pf)\n",
    "        cars = pickle_carpics[\"cars\"]\n",
    "        notcars = pickle_carpics[\"notcars\"]\n",
    "        udacity_cars = pickle_carpics[\"udacity_cars\"]\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "car_features = extract_features(cars, w_bboxes=False, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=extract_spatial_features, \n",
    "                        hist_feat=extract_hist_bins_features, hog_feat=extract_hog_features)\n",
    "notcar_features = extract_features(notcars, w_bboxes=False, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=extract_spatial_features, \n",
    "                        hist_feat=extract_hist_bins_features, hog_feat=extract_hog_features)\n",
    "#udacity_cars_features = extract_features(udacity_cars, w_bboxes=True, color_space=color_space, \n",
    "#                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                        cell_per_block=cell_per_block, \n",
    "#                        hog_channel=hog_channel, spatial_feat=extract_spatial_features, \n",
    "#                        hist_feat=extract_hist_bins_features, hog_feat=extract_hog_features)\n",
    "\n",
    "# Saving classifier to pickle file\n",
    "pickle_features = { \"car_features\" : car_features, \"notcar_features\" : notcar_features, \\\n",
    "                    \"udacity_cars_features\" : udacity_cars_features }\n",
    "with open('features.' + color_space.lower() + '.p', 'wb') as pf:\n",
    "    pickle.dump(pickle_features, pf)\n",
    "    print('pickle file saved successfully!')\n",
    "    pf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate images for write-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "if os.path.isfile('carpics.p'):\n",
    "    with open('carpics.p', 'rb') as pf:\n",
    "        pickle_carpics = pickle.load(pf)\n",
    "        cars = pickle_carpics[\"cars\"]\n",
    "        notcars = pickle_carpics[\"notcars\"]\n",
    "        udacity_cars = pickle_carpics[\"udacity_cars\"]\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "car_img = mpimg.imread(cars[100])\n",
    "notcar_img = mpimg.imread(notcars[100])\n",
    "udacity_cars_img = mpimg.imread('object-detection-crowdai/' + udacity_cars[0][\"file\"])\n",
    "udacity_cars_cvt = convert_color(udacity_cars_img, conv='HLS')\n",
    "\n",
    "car_img_cvt = convert_color(car_img, conv='HSV')\n",
    "notcar_img_cvt = convert_color(notcar_img, conv='HSV')\n",
    "car_img_features, car_img_hog_image = hog(car_img[:,:,0], orientations=orient, \n",
    "                                          pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                          cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                          transform_sqrt=False, \n",
    "                                          visualise=True, feature_vector=True)\n",
    "notcar_img_features, notcar_img_hog_image = hog(notcar_img[:,:,0], orientations=orient, \n",
    "                                                pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                                cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                                transform_sqrt=False, \n",
    "                                                visualise=True, feature_vector=True)\n",
    "plt.figure()\n",
    "plt.imshow(car_img_cvt)\n",
    "plt.figure()\n",
    "plt.imshow(notcar_img_cvt)\n",
    "plt.figure()\n",
    "plt.imshow(udacity_cars_cvt)\n",
    "plt.figure()\n",
    "plt.imshow(car_img_hog_image)\n",
    "plt.figure()\n",
    "plt.imshow(notcar_img_hog_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbec9313320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "test6_image = mpimg.imread('./test_images/test6.jpg')\n",
    "plt.figure()\n",
    "plt.imshow(test6_image)\n",
    "test2_image = mpimg.imread('./test_images/test2.jpg')\n",
    "plt.figure()\n",
    "plt.imshow(test2_image)\n",
    "test4_image = mpimg.imread('./test_images/test4.jpg')\n",
    "plt.figure()\n",
    "plt.imshow(test4_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Restore previously saved classifier and scaler\n",
    "if os.path.isfile('features.' + color_space.lower() + '.p'):\n",
    "    with open('features.' + color_space.lower() + '.p', 'rb') as pf:\n",
    "        pickle_features = pickle.load(pf)\n",
    "        car_features = pickle_features[\"car_features\"]\n",
    "        notcar_features = pickle_features[\"notcar_features\"]\n",
    "        udacity_cars_features = pickle_features[\"udacity_cars_features\"]\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "        \n",
    "udacity_cars_features = udacity_cars_features[0:int(len(udacity_cars_features)/3)]\n",
    "        \n",
    "# flags for enabling training with various classifiers\n",
    "fancy_training = False\n",
    "grid_search_training = False\n",
    "\n",
    "#X = np.vstack((car_features, notcar_features, udacity_cars_features)).astype(np.float64)\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "#y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features)), np.ones(len(udacity_cars_features))))\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "if fancy_training:\n",
    "    # enable grid search\n",
    "    if grid_search_training:\n",
    "        svr = SVC()\n",
    "        # try radial basis function, polynomial, various C and gamma values\n",
    "        search_parameters = { 'kernel': ('rbf', 'poly'), \\\n",
    "                              'C' : np.logspace(-1,1,3), \\\n",
    "                              'gamma': np.logspace(-7,1,3) }\n",
    "        clf = GridSearchCV(svr, search_parameters, scoring='accuracy', verbose=10)\n",
    "    else:\n",
    "        # Use a radial basis function\n",
    "        clf = SVC(kernel='rbf')\n",
    "else:\n",
    "    # Use a linear SVC\n",
    "    clf = LinearSVC()\n",
    "\n",
    "\n",
    "# Check the training time\n",
    "t=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train classifer...')\n",
    "\n",
    "# Check the score of the classifier\n",
    "print('Test Accuracy of classifier = ', round(clf.score(X_test, y_test), 4))\n",
    "\n",
    "# Saving classifier to pickle file\n",
    "pickle_clf = { \"clf\" : clf, \"X_scaler\" : X_scaler }\n",
    "with open('clf_scaler.' + color_space.lower() + '.p', 'wb') as pf:\n",
    "    pickle.dump(pickle_clf, pf)\n",
    "    print('pickle file saved successfully!')\n",
    "    pf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define window search function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def search_window(img, ystart, ystop, scale, clf, X_scaler, window, orient, pix_per_cell, \\\n",
    "                  cell_per_block, hog_channel, color_space, spatial_size, hist_bins, \\\n",
    "                  spatial_feat=True, hist_feat=True, hog_feat=True, output_img=False):\n",
    "    \n",
    "    Debug = False\n",
    "    draw_img = np.copy(img)\n",
    "    if (np.max(img) > 1.0):\n",
    "        img = img.astype(np.float32)/255\n",
    "    else:\n",
    "        img = img.astype(np.float32)\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv=color_space)\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps.\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1\n",
    "    if Debug:\n",
    "        print(\"\\n\\nscale {}\".format(scale))\n",
    "        print(\"ch1.shape {}\".format(ch1.shape))\n",
    "    \n",
    "    # window steps\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    # Instead of overlap, define how many cells to step\n",
    "    cells_per_step_x = 2\n",
    "    cells_per_step_y = 2\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step_x + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step_y + 1\n",
    "    if Debug:\n",
    "        print(\"nysteps {}\".format(nysteps))\n",
    "    \n",
    "    bboxes = []\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    if hog_feat:\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb*cells_per_step_x\n",
    "                xpos = xb*cells_per_step_y\n",
    "                \n",
    "                # Extract HOG for this patch\n",
    "                if hog_channel is 0:\n",
    "                    hog_features = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                elif hog_channel is 1:\n",
    "                    hog_features = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                elif hog_channel is 2:\n",
    "                    hog_features = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                elif hog_channel is \"ALL\":\n",
    "                    hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                    hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                xleft = xpos*pix_per_cell\n",
    "                ytop = ypos*pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "            \n",
    "                # Get color features\n",
    "                if spatial_feat:\n",
    "                    spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                if hist_feat:\n",
    "                    hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "                \n",
    "                # Scale features and make a prediction\n",
    "                feature_vec = []\n",
    "                if spatial_feat:\n",
    "                    feature_vec.append(spatial_features)\n",
    "                if hist_feat:\n",
    "                    feature_vec.append(hist_features)\n",
    "                if hog_feat:\n",
    "                    feature_vec.append(hog_features)\n",
    "                \n",
    "                features = np.concatenate(feature_vec).astype(np.float64)\n",
    "                if Debug:\n",
    "                    print(\"hog_features {}\".format(len(hog_features)))\n",
    "                    print(\"hist_features {}\".format(len(hist_features)))\n",
    "                    print(\"spatial_features {}\".format(len(spatial_features)))\n",
    "                test_features = X_scaler.transform(features.reshape(1, -1)) \n",
    "                test_prediction = clf.predict(test_features)\n",
    "            \n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    x1_y1 = (xbox_left, ytop_draw+ystart)\n",
    "                    x2_y2 = (xbox_left+win_draw,ytop_draw+win_draw+ystart)\n",
    "                    bboxes.append((x1_y1, x2_y2))\n",
    "                    if output_img:\n",
    "                        cv2.rectangle(draw_img, x1_y1, x2_y2, (0,0,255), 6)\n",
    "    \n",
    "    if output_img:\n",
    "        return bboxes, draw_img\n",
    "    else:\n",
    "        return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_roi(input_image, y_min, y_max, scaling_factors, clf, X_scaler, win_size, orient, \\\n",
    "                                                              pix_per_cell, cell_per_block, \\\n",
    "                                                              hog_channel, color_space, spatial_size, hist_bins, \\\n",
    "                                                              spatial_feat, hist_feat, hog_feat, output_img=False):\n",
    "    bboxes_list = []\n",
    "    for scale in scaling_factors:\n",
    "    \n",
    "        ystart = y_min\n",
    "        y_min = np.int(ystart + (y_max-y_min)/len(scaling_factors))\n",
    "            \n",
    "        if output_img:\n",
    "            bboxes, input_image = search_window(input_image, ystart, y_min, scale, \\\n",
    "                                             clf, X_scaler, win_size, orient, pix_per_cell, cell_per_block, \\\n",
    "                                             hog_channel, color_space, spatial_size, hist_bins, \\\n",
    "                                             spatial_feat, hist_feat, hog_feat, output_img)\n",
    "        else:\n",
    "            bboxes = search_window(input_image, ystart, y_min, scale, \\\n",
    "                                             clf, X_scaler, win_size, orient, pix_per_cell, cell_per_block, \\\n",
    "                                             hog_channel, color_space, spatial_size, hist_bins, \\\n",
    "                                             spatial_feat, hist_feat, hog_feat, output_img)\n",
    "        bboxes_list.extend(bboxes)\n",
    "    \n",
    "    if output_img:\n",
    "        return bboxes_list, input_image\n",
    "    else:\n",
    "        return bboxes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global search parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_min = 400\n",
    "y_max = 720\n",
    "# different scaling steps applied along y axis\n",
    "scaling_factors = (1.4, 2)\n",
    "win_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boldorider4/Applications/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LinearSVC from version 0.18.1 when using version 0.18. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/boldorider4/Applications/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator StandardScaler from version 0.18.1 when using version 0.18. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file restored successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# Restore previously saved classifier and scaler\n",
    "if os.path.isfile('clf_scaler.' + color_space.lower() + '.p'):\n",
    "    with open('clf_scaler.' + color_space.lower() + '.p', 'rb') as pf:\n",
    "        pickle_clf = pickle.load(pf)\n",
    "        clf = pickle_clf[\"clf\"]\n",
    "        X_scaler = pickle_clf[\"X_scaler\"]\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "# test images\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "test_bboxes = []\n",
    "\n",
    "for test_img in test_images:\n",
    "\n",
    "    # load test image\n",
    "    test_img = mpimg.imread(test_img)\n",
    "    \n",
    "    # search ROI in image and output both bounding boxes and image with bounding boxes drawn upon them for debugging\n",
    "    bboxes, test_img = search_roi(test_img, y_min, y_max, scaling_factors, clf, X_scaler, win_size, orient, \\\n",
    "                                  pix_per_cell, cell_per_block, hog_channel, color_space, spatial_size, hist_bins, \\\n",
    "                                  spatial_feat=extract_spatial_features, hist_feat=extract_hist_bins_features, \\\n",
    "                                  hog_feat=extract_hog_features, output_img=True)\n",
    "    \n",
    "    test_bboxes.append(bboxes)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate heat images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    bboxes = []\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        bboxes.append(bbox)\n",
    "    # Return the image\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final detection pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "boxhistory = deque([])\n",
    "boxhistory_length = 10\n",
    "\n",
    "def detection_pipeline(input_image):\n",
    "    \n",
    "    global scaling_factors, clf, X_scaler, win_size, orient, pix_per_cell, cell_per_block, \\\n",
    "           hog_channel, spatial_size, hist_bins, extract_spatial_features, extract_hist_bins_features, \\\n",
    "           extract_hog_features, boxhistoryList, Debug\n",
    "    \n",
    "    # generate empty heat map\n",
    "    heat = np.zeros_like(input_image[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # find bounding boxes\n",
    "    bboxes = search_roi(input_image, y_min, y_max, scaling_factors, clf, X_scaler, win_size, orient, \\\n",
    "                        pix_per_cell, cell_per_block, hog_channel, color_space, spatial_size, hist_bins, \\\n",
    "                        spatial_feat=extract_spatial_features, hist_feat=extract_hist_bins_features, \\\n",
    "                        hog_feat=extract_hog_features, output_img=False)\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat, bboxes)\n",
    "    \n",
    "    # debug dict for storing intermediate pipeline stages\n",
    "    returned_debug = {}\n",
    "    \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,2)\n",
    "    if Debug:\n",
    "        returned_debug[\"heat\"] = np.copy(heat)\n",
    "\n",
    "    # Visualize the heatmap when displaying\n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    if Debug:\n",
    "        returned_debug[\"labels\"] = np.copy(labels)\n",
    "    bboxes_labeled = draw_labeled_bboxes(np.copy(input_image), labels)\n",
    "    debug_drawn_boxes = np.copy(input_image)\n",
    "    for bbox in bboxes_labeled:\n",
    "        cv2.rectangle(debug_drawn_boxes, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    if Debug:\n",
    "        returned_debug[\"debug_drawn_boxes\"] = debug_drawn_boxes\n",
    "    \n",
    "    if len(boxhistory) >= boxhistory_length:\n",
    "        boxhistory.popleft()\n",
    "    boxhistory.append(bboxes_labeled)\n",
    "    \n",
    "    heat = np.zeros_like(input_image[:,:,0]).astype(np.float)\n",
    "    for bboxes in boxhistory:\n",
    "        heat = add_heat(heat, bboxes)\n",
    "    \n",
    "    heat = apply_threshold(heat,3)\n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    labels = label(heatmap)\n",
    "    bboxes_labeled = draw_labeled_bboxes(np.copy(input_image), labels)\n",
    "    \n",
    "    # Draw the box on the image\n",
    "    output_img = np.copy(input_image)\n",
    "    for bbox in bboxes_labeled:\n",
    "        cv2.rectangle(output_img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    \n",
    "    if Debug:\n",
    "        return output_img, returned_debug\n",
    "    else:\n",
    "        return output_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Apply entire pipeline on test images results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "Debug = True\n",
    "\n",
    "if len(test_images) is not len(test_bboxes):\n",
    "    print(\"Error: number of bboxes doesn't match number of test images\")\n",
    "else:\n",
    "    for img_idx in range(len(test_images)):\n",
    "\n",
    "        test_img = mpimg.imread(test_images[img_idx])\n",
    "        if Debug:\n",
    "            draw_img, debug = detection_pipeline(test_img)\n",
    "\n",
    "        if Debug:\n",
    "            plt.figure()\n",
    "            plt.imshow(debug[\"heat\"])\n",
    "            if [len(debug[\"labels\"]) > 0]:\n",
    "                plt.figure()\n",
    "                plt.imshow(debug[\"labels\"][0])\n",
    "            plt.figure()\n",
    "            plt.imshow(debug[\"debug_drawn_boxes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply vehicle detection on video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell #16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "import os\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# Restore previously saved classifier and scaler\n",
    "if os.path.isfile('clf_scaler.' + color_space.lower() + '.p'):\n",
    "    with open('clf_scaler.' + color_space.lower() + '.p', 'rb') as pf:\n",
    "        pickle_clf = pickle.load(pf)\n",
    "        clf = pickle_clf[\"clf\"]\n",
    "        X_scaler = pickle_clf[\"X_scaler\"]\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "        \n",
    "Debug = False\n",
    "\n",
    "video_output_file = 'project_video_out.mp4'\n",
    "video_input = VideoFileClip(\"project_video.mp4\")\n",
    "    \n",
    "# For debugging purposes, some stages of the pipeline stages can be outputted while\n",
    "# running the lane finding on the video frames\n",
    "if not Debug:\n",
    "    video_output = video_input.fl_image(detection_pipeline)\n",
    "    %time video_output.write_videofile(video_output_file, audio=False)\n",
    "else:\n",
    "    for t in np.linspace(30, 34, 10):\n",
    "        image = video_input.get_frame(t)\n",
    "        print('\\ntime {}'.format(t))\n",
    "        found_cars = detection_pipeline(image)\n",
    "        #found_cars = image\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(found_cars)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
