{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Computing the camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "image_path = 'camera_cal'\n",
    "file_count = 0\n",
    "\n",
    "# for each calibration image file in 'camera_cal'\n",
    "for file in [f for f in os.listdir(image_path) if f.startswith(\"calibration\") and f.endswith('.jpg')]:\n",
    "    image = cv2.imread(os.path.join(image_path, file))\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners                                                                                                                                                                        \n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    # If found, draw corners\n",
    "    if ret == True:\n",
    "        imgpoints.append(corners)\n",
    "        cv2.drawChessboardCorners(image, (nx, ny), corners, ret)\n",
    "        file_out = re.split('.jpg', file)[0] + '_cornersdrawn.jpg'\n",
    "        cv2.imwrite(os.path.join('output_images', file_out), image)\n",
    "        file_count += 1\n",
    "        # Draw and display the corners on two sample images\n",
    "        if (file.endswith('calibration2.jpg') or file.endswith('calibration13.jpg')) and False: # see if these\n",
    "            plt.figure()                                                                        # are necessary\n",
    "            plt.imshow(image)\n",
    "\n",
    "objpoints = np.array([objp]*file_count) # 3d points in real world space\n",
    "\n",
    "# Calibrate the camera\n",
    "retval, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "if retval >= 0:\n",
    "    print('Calibration is successful!')\n",
    "    # Saving camera parameters to pickle file\n",
    "    camera_params = { \"mtx\": mtx, \\\n",
    "                      \"dist\": dist, \\\n",
    "                      \"rvecs\": rvecs, \\\n",
    "                      \"tvecs\": tvecs }\n",
    "    with open('camera_params.p', 'wb') as pf:\n",
    "        pickle.dump(camera_params, pf)\n",
    "        print('pickle file saved successfully!')\n",
    "        pf.close()\n",
    "else:\n",
    "    print('Something went wrong with the calibration...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying distorsion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "# Restore previously found values\n",
    "if os.path.isfile('camera_params.p'):\n",
    "    with open('camera_params.p', 'rb') as pf:\n",
    "        camera_params = pickle.load(pf)\n",
    "        mtx, dist, rvecs, tvecs = camera_params[\"mtx\"], camera_params[\"dist\"], \\\n",
    "                                  camera_params[\"rvecs\"], camera_params[\"tvecs\"]\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "# Undistort the calibration images, just for putting them in the writeup\n",
    "image_path = 'camera_cal'\n",
    "for file in [f for f in os.listdir(image_path) if f.startswith(\"calibration\") and f.endswith('.jpg')]:\n",
    "    image = cv2.imread(os.path.join(image_path, file))\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    file_out = re.split('.jpg', file)[0] + '_undistort.jpg'\n",
    "    cv2.imwrite(os.path.join('output_images', file_out), undist)\n",
    "    if (file.endswith('calibration2.jpg') or file.endswith('calibration13.jpg')) and False: # see if these\n",
    "        plt.figure()                                                                        # are necessary\n",
    "        plt.imshow(undist)\n",
    "\n",
    "# Undistort the example images        \n",
    "image_path = 'test_images'\n",
    "for file in [f for f in os.listdir(image_path) if f.endswith('.jpg')]:\n",
    "    image = cv2.imread(os.path.join(image_path, file))\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    file_out = re.split('.jpg', file)[0] + '_undistort.jpg'\n",
    "    cv2.imwrite(os.path.join('output_images', file_out), undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creating a thresholded binary image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of processing blocks and ultimate pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def sobel_x(channel, ker_size=3):\n",
    "    return cv2.Sobel(channel, cv2.CV_64F, 1, 0, ksize=ker_size)\n",
    "\n",
    "def sobel_y(channel, ker_size=3):\n",
    "    return cv2.Sobel(channel, cv2.CV_64F, 0, 1, ksize=ker_size)\n",
    "\n",
    "def scale_thresh_image(channel, thresh=(0, 255)):\n",
    "    scaled_ch = np.uint8(255*channel/np.max(channel))\n",
    "    binary_img = np.zeros_like(scaled_ch)\n",
    "    binary_img[(scaled_ch >= thresh[0]) & (scaled_ch < thresh[1])] = 1\n",
    "    return binary_img\n",
    "\n",
    "def sobel_thresh(channel, orient, ker_size=3, thresh=(0, 255)):\n",
    "    if orient is 'x':\n",
    "        sobel = sobel_x(channel, ker_size)\n",
    "    elif orient is 'y':\n",
    "        sobel = sobel_y(channel, ker_size)\n",
    "    else:\n",
    "        print('invalid sobel orientation')\n",
    "        exit(-1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    return scale_thresh_image(abs_sobel, thresh)\n",
    "\n",
    "def mag_thresh(channel, ker_size=3, thresh=(0, 255)):\n",
    "    sobelx = sobel_x(channel, ker_size)\n",
    "    sobely = sobel_y(channel, ker_size)\n",
    "    mag_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    return scale_thresh_image(mag_sobel, thresh)\n",
    "    \n",
    "def dir_thresh(channel, ker_size=3, thresh=(-np.pi*70/180, np.pi*70/180)):\n",
    "    sobelx = sobel_x(channel, ker_size)\n",
    "    sobely = sobel_y(channel, ker_size)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    arctan_sobel = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    binary_img = np.zeros_like(arctan_sobel)\n",
    "    binary_img[(arctan_sobel >= thresh[0]) & (arctan_sobel < thresh[1])] = 1\n",
    "    return binary_img\n",
    "\n",
    "def thresholding_pipeline(img, Debug=False):\n",
    "    # Convert to HSV color space\n",
    "    hsl = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    h_channel = hsl[:,:,0]\n",
    "    l_channel = hsl[:,:,1]\n",
    "    s_channel = hsl[:,:,2]\n",
    "\n",
    "    # Convert to gray scale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY).astype(np.int16)\n",
    "\n",
    "    # Thresholded scaled gray scale\n",
    "    thresh_scale_gray = scale_thresh_image(gray, (190, 255))\n",
    "\n",
    "    # Thresholded sobel x on S channel\n",
    "    sobelx_s = sobel_thresh(s_channel, 'x', 11, (40, 100))\n",
    "\n",
    "    binary_output = np.zeros_like(gray).astype(np.uint8)\n",
    "    \n",
    "    result_dict = {}\n",
    "    # expand result dict with other combinations of binary images for debugging purposes\n",
    "    if Debug:\n",
    "        # Thresholded scaled S channel\n",
    "        thresh_scale_s = scale_thresh_image(s_channel, (200, 255)) \n",
    "        # Thresholded scaled L channel\n",
    "        thresh_scale_l = scale_thresh_image(l_channel, (200, 255))\n",
    "        # Thresholded sobel x on gray channel\n",
    "        sobelx_gray = sobel_thresh(gray, 'x', 13, (30, 80))\n",
    "        # Thresholded directional sobel on S channel\n",
    "        dir_thresh_s = dir_thresh(s_channel, 7, (np.pi*40/180, np.pi*70/180))\n",
    "        \n",
    "        # Putting debug thresholded images in returned dictionary\n",
    "        result_dict[\"thresh_scale_l\"] = thresh_scale_l\n",
    "        result_dict[\"thresh_scale_s\"] = thresh_scale_s\n",
    "        result_dict[\"thresh_scale_gray\"] = thresh_scale_gray\n",
    "        result_dict[\"sobelx_gray\"] = sobelx_gray\n",
    "        result_dict[\"sobelx_s\"] = sobelx_s\n",
    "        result_dict[\"dir_thresh_s\"] = dir_thresh_s\n",
    "        \n",
    "        binary_output[(thresh_scale_gray == 1) | (sobelx_s == 1)] = 1\n",
    "        result_dict[\"binary_output_tsg_sxs\"] = binary_output\n",
    "        binary_output = np.zeros_like(gray).astype(np.uint8)\n",
    "        binary_output[(thresh_scale_s == 1) | (thresh_scale_gray == 1) | (sobelx_s == 1)] = 1\n",
    "        result_dict[\"binary_output_tss_tsg_sxs\"] = binary_output\n",
    "        binary_output = np.zeros_like(gray).astype(np.uint8)\n",
    "        binary_output[(thresh_scale_l == 1) | (sobelx_gray == 1)] = 1\n",
    "        result_dict[\"binary_output_tsl_sxg\"] = binary_output\n",
    "        binary_output = np.zeros_like(gray).astype(np.uint8)\n",
    "        binary_output[(thresh_scale_l == 1) | (sobelx_s == 1)] = 1\n",
    "        result_dict[\"binary_output_tsl_sxs\"] = binary_output\n",
    "    else:   \n",
    "        binary_output[(thresh_scale_gray == 1) | (sobelx_s == 1)] = 1\n",
    "        result_dict[\"binary_output_tsg_sxs\"] = binary_output\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running single blocks and complete pipeline on example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "#%matplotlib inline\n",
    "%matplotlib qt\n",
    "\n",
    "image_path = 'output_images'\n",
    "binary_img_list = []\n",
    "\n",
    "for file in [f for f in os.listdir(image_path) if \\\n",
    "             (f.startswith('straight_lines') or f.startswith('test'))]:\n",
    "\n",
    "    image = mpimg.imread(os.path.join(image_path, file))\n",
    "    binary_img = thresholding_pipeline(image)\n",
    "    binary_img = binary_img[\"binary_output_tsg_sxs\"]\n",
    "    binary_img_list.append(binary_img)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(binary_img, cmap='gray')\n",
    "    \n",
    "# Saving binary images to pickle file\n",
    "with open('binary_images.p', 'wb') as pf:\n",
    "    pickle.dump(binary_img_list, pf)\n",
    "    print('pickle file saved successfully!')\n",
    "    pf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline                                                                                                                                                                                  \n",
    "#%matplotlib qt\n",
    "\n",
    "# Restore previously saved binary images\n",
    "if os.path.isfile('binary_images.p'):\n",
    "    with open('binary_images.p', 'rb') as pf:\n",
    "        binary_img_list = pickle.load(pf)\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "# The source points were eyeballed from the binary images resulting from processing\n",
    "# the test images\n",
    "src_points = np.float32(\n",
    "    [[547,  472],\n",
    "     [764,  472],\n",
    "     [1280, 702],\n",
    "     [290,  702]])\n",
    "\n",
    "# The destination points correspond to a full 1280x720 frame\n",
    "dst_points = np.float32(\n",
    "    [[0,     0],\n",
    "     [1280,  0],\n",
    "     [1280, 720],\n",
    "     [155.5,720]])\n",
    "\n",
    "# Compute the transform and inverse transform matrices\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "Minv = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "warped_img_list = []\n",
    "\n",
    "for idx in range(0,8):\n",
    "    image = binary_img_list[idx]\n",
    "    warped = cv2.warpPerspective(image, M, image.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "    warped_img_list.append(warped)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(warped, cmap='gray')\n",
    "    \n",
    "# Saving warped images to pickle file\n",
    "with open('warped_images.p', 'wb') as pf:\n",
    "    pickle.dump(warped_img_list, pf)\n",
    "    print('pickle file saved successfully!')\n",
    "    pf.close()\n",
    "# Saving transform matrices to pickle file\n",
    "transform_matrices = { \"M\": M, \"Minv\": Minv }\n",
    "with open('transform_matrices.p', 'wb') as pf:\n",
    "    pickle.dump(transform_matrices, pf)\n",
    "    print('pickle file saved successfully!')\n",
    "    pf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting lane boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline                                                                                                                                                                                  \n",
    "#%matplotlib qt\n",
    "\n",
    "\n",
    "def find_lanes_full_search(image, nwindows=9, margin=100, minpix=50, Debug=False):\n",
    "\n",
    "    histogram = np.sum(image[image.shape[0]//2:,:], axis=0)\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(image.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    left_rectangle_coords = []\n",
    "    right_rectangle_coords = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = image.shape[0] - (window+1)*window_height\n",
    "        win_y_high = image.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        left_rectangle_coords.append((win_xleft_low,win_y_low,win_xleft_high,win_y_high))\n",
    "        right_rectangle_coords.append((win_xright_low,win_y_low,win_xright_high,win_y_high))\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \\\n",
    "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \\\n",
    "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    result_dict = {}\n",
    "    # Extract left and right line pixel positions\n",
    "    result_dict[\"leftx\"] = nonzerox[left_lane_inds]\n",
    "    result_dict[\"lefty\"] = nonzeroy[left_lane_inds]\n",
    "    result_dict[\"rightx\"] = nonzerox[right_lane_inds]\n",
    "    result_dict[\"righty\"] = nonzeroy[right_lane_inds]\n",
    "    if Debug:\n",
    "        result_dict[\"left_rectangle_coords\"] = left_rectangle_coords\n",
    "        result_dict[\"right_rectangle_coords\"] = right_rectangle_coords\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "    \n",
    "def find_lane_quick_search(image, left_fit, right_fit, margin=100):\n",
    "    \n",
    "    # Identify the nonzero pixels in x and y within a margin from the previously fit line\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) \\\n",
    "                      & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) \\\n",
    "                       & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    result_dict[\"leftx\"] = nonzerox[left_lane_inds]\n",
    "    result_dict[\"lefty\"] = nonzeroy[left_lane_inds]\n",
    "    result_dict[\"rightx\"] = nonzerox[right_lane_inds]\n",
    "    result_dict[\"righty\"] = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To demonstrate the full lane search, here follows the application of the latter to all example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline                                                                                                                                                                                  \n",
    "#%matplotlib qt\n",
    "\n",
    "# Restore previously saved warped images\n",
    "if os.path.isfile('warped_images.p'):\n",
    "    with open('warped_images.p', 'rb') as pf:\n",
    "        warped_img_list = pickle.load(pf)\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "\n",
    "leftx_test_images = []\n",
    "lefty_test_images = []\n",
    "rightx_test_images = []\n",
    "righty_test_images = []\n",
    "\n",
    "for idx in range(0,8):\n",
    "    \n",
    "    # Perform full lane search\n",
    "    ret_dict = find_lanes_full_search(warped_img_list[idx], nwindows, margin, minpix, Debug=True)\n",
    "    \n",
    "    leftx = ret_dict[\"leftx\"]\n",
    "    lefty = ret_dict[\"lefty\"]\n",
    "    rightx = ret_dict[\"rightx\"]\n",
    "    righty = ret_dict[\"righty\"]\n",
    "    leftrect_coords = ret_dict[\"left_rectangle_coords\"]\n",
    "    rightrect_coords = ret_dict[\"right_rectangle_coords\"]\n",
    "    \n",
    "    leftx_test_images.append(leftx)\n",
    "    lefty_test_images.append(lefty)\n",
    "    rightx_test_images.append(rightx)\n",
    "    righty_test_images.append(righty)\n",
    "    \n",
    "    # Image canvas to plot lanes data\n",
    "    out_img = np.dstack((warped_img_list[idx], warped_img_list[idx], warped_img_list[idx]))*255\n",
    "    \n",
    "    # Draw the windows on the visualization image\n",
    "    for window in range(nwindows):\n",
    "        cv2.rectangle(out_img,(leftrect_coords[window][0],leftrect_coords[window][1]), \\\n",
    "                              (leftrect_coords[window][2],leftrect_coords[window][3]), (0,255,0), 2)\n",
    "        cv2.rectangle(out_img,(rightrect_coords[window][0],rightrect_coords[window][1]), \\\n",
    "                              (rightrect_coords[window][2],rightrect_coords[window][3]), (0,255,0), 2)\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, warped_img_list[idx].shape[0]-1, warped_img_list[idx].shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Color points detected in each lane rectangular search area\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    # Plot everything on out_img\n",
    "    plt.figure()\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    \n",
    "# Saving curve points to pickle file\n",
    "lane_curve_points = { \"leftx_test_images\": leftx_test_images, \\\n",
    "                      \"lefty_test_images\": lefty_test_images, \\\n",
    "                      \"rightx_test_images\": rightx_test_images, \\\n",
    "                      \"righty_test_images\": righty_test_images }\n",
    "with open('lane_curve_points.p', 'wb') as pf:\n",
    "    pickle.dump(lane_curve_points, pf)\n",
    "    print('pickle file saved successfully!')\n",
    "    pf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To demonstrate a quick lane search based on previously determined lane curve coefficients, here follows the lane curve detection of test_image6 based on the coefficients found for in test_image5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore previously saved curve points images\n",
    "if os.path.isfile('lane_curve_points.p'):\n",
    "    with open('lane_curve_points.p', 'rb') as pf:\n",
    "        lane_curve_points = pickle.load(pf)\n",
    "        leftx_test_images = lane_curve_points[\"leftx_test_images\"]\n",
    "        lefty_test_images = lane_curve_points[\"lefty_test_images\"]\n",
    "        rightx_test_images = lane_curve_points[\"rightx_test_images\"]\n",
    "        righty_test_images = lane_curve_points[\"righty_test_images\"]\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "# Retrieve left and right lane curve fit for test_image5\n",
    "left_fit_test_image5 = np.polyfit(lefty_test_images[4], leftx_test_images[4], 2)\n",
    "right_fit_test_image5 = np.polyfit(righty_test_images[4], rightx_test_images[4], 2)\n",
    "# Use warped image from test_image6\n",
    "warped_test_image6 = warped_img_list[5]\n",
    "\n",
    "# Perform a lane search based on previous example image\n",
    "ret_dict = find_lane_quick_search(warped_test_image6, left_fit_test_image5, right_fit_test_image5, margin)\n",
    "leftx = ret_dict[\"leftx\"]\n",
    "lefty = ret_dict[\"lefty\"]\n",
    "rightx = ret_dict[\"rightx\"]\n",
    "righty = ret_dict[\"righty\"]\n",
    "\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, warped_test_image6.shape[0]-1, warped_test_image6.shape[0])\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# Create an image to draw on and an image to show the selection window\n",
    "out_img = np.dstack((warped_test_image6, warped_test_image6, warped_test_image6))*255\n",
    "window_img = np.zeros_like(out_img)\n",
    "# Color in left and right line pixels\n",
    "out_img[lefty, leftx] = [255, 0, 0]\n",
    "out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255,0))\n",
    "cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255,0))\n",
    "result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "plt.figure()\n",
    "plt.imshow(result)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting curvature and vehicle position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_curvature(curve_fit, y_eval):\n",
    "    return ((1 + (2*curve_fit[0]*y_eval + curve_fit[1])**2)**1.5) / np.absolute(2*curve_fit[0])\n",
    "\n",
    "def get_lane_x_coord(curve_fit, y_eval):\n",
    "    return curve_fit[0]*y_eval**2 + curve_fit[1]*y_eval + curve_fit[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting curvature values in pixels and meters for the test images\n",
    "#### The order of the images that was used to derive the curvature values follows how the image thresholding pipeline was applied:\n",
    "1. straight_lines2_undistort.jpg\n",
    "2. test4_undistort.jpg\n",
    "3. test6_undistort.jpg\n",
    "4. straight_lines1_undistort.jpg\n",
    "5. test3_undistort.jpg\n",
    "6. test1_undistort.jpg\n",
    "7. test2_undistort.jpg\n",
    "8. test5_undistort.jpg\n",
    "\n",
    "#### N.B.: the values of curvature can be extremely noisy and have to be ultimately smoothened!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Restore previously saved curve points images\n",
    "if os.path.isfile('lane_curve_points.p'):\n",
    "    with open('lane_curve_points.p', 'rb') as pf:\n",
    "        lane_curve_points = pickle.load(pf)\n",
    "        leftx_test_images = lane_curve_points[\"leftx_test_images\"]\n",
    "        lefty_test_images = lane_curve_points[\"lefty_test_images\"]\n",
    "        rightx_test_images = lane_curve_points[\"rightx_test_images\"]\n",
    "        righty_test_images = lane_curve_points[\"righty_test_images\"]\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "# Bottom of image is chosen to evaluate curvature\n",
    "y_eval = np.max(719)\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "# This conversions stems from taking rough measurements on the test images\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/1080 # meters per pixel in x dimension\n",
    "\n",
    "for idx in range(0,8):\n",
    "\n",
    "    # Fit polynomials to x,y in pixel space\n",
    "    left_fit = np.polyfit(lefty_test_images[idx], leftx_test_images[idx], 2)\n",
    "    right_fit = np.polyfit(righty_test_images[idx], rightx_test_images[idx], 2)\n",
    "    # Calculate curvature\n",
    "    left_curverad = get_curvature(left_fit, y_eval)\n",
    "    right_curverad = get_curvature(right_fit, y_eval)\n",
    "\n",
    "    print(\"test image {} curvature:\".format(idx+1))\n",
    "    print(\"left {} px, right {} px\".format(int(left_curverad), int(right_curverad)))\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty_test_images[idx]*ym_per_pix, leftx_test_images[idx]*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty_test_images[idx]*ym_per_pix, rightx_test_images[idx]*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curvem = get_curvature(left_fit_cr, y_eval*ym_per_pix)\n",
    "    right_curvem = get_curvature(right_fit_cr, y_eval*ym_per_pix)\n",
    "    \n",
    "    print(\"left {} m, right {} m\".format(int(left_curvem), int(right_curvem)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on videoclip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading camera parameters and transform matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Restore previously saved binary images\n",
    "if os.path.isfile('camera_params.p'):\n",
    "    with open('camera_params.p', 'rb') as pf:\n",
    "        camera_params = pickle.load(pf)\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "# Restore previously saved binary images\n",
    "if os.path.isfile('transform_matrices.p'):\n",
    "    with open('transform_matrices.p', 'rb') as pf:\n",
    "        transform_matrices = pickle.load(pf)\n",
    "        print('pickle file restored successfully!')\n",
    "        pf.close()\n",
    "\n",
    "mtx, dist, M, Minv = camera_params[\"mtx\"], camera_params[\"dist\"], transform_matrices[\"M\"], transform_matrices[\"Minv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a class for the lane line currently detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # coefficients of the last n fits of the line\n",
    "        self.recent_fits = deque([])\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        # curvature of the last n fits of the line\n",
    "        self.recent_curvs = deque([])\n",
    "        # lane line curvature\n",
    "        self.curv = None\n",
    "        # lane line x and y coords\n",
    "        self.allx = None\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function for performing sanity checks on lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "min_valid_curve_points = 500\n",
    "lane_width_diff_tolerance = .5\n",
    "curvature_diff_tolerance = 1.6\n",
    "lane_pos_tolerance = .2\n",
    "lane_history_size = 5\n",
    "    \n",
    "def sanity_check(linehist_l, linehist_r, lefty, leftx, righty, rightx, xm_per_pix, \\\n",
    "                 ym_per_pix, image_size, verbose=False):\n",
    "    \n",
    "    global min_valid_curve_points, lane_width_diff_tolerance, curvature_diff_tolerance, \\\n",
    "           lane_pos_tolerance, lane_history_size\n",
    "    \n",
    "    linehist_l.detected = False if lefty.size < min_valid_curve_points else True\n",
    "    linehist_r.detected = False if righty.size < min_valid_curve_points else True\n",
    "    if verbose:\n",
    "        print(\"lx lane n of points {}\".format(lefty.size))\n",
    "        print(\"rx lane n of points {}\".format(righty.size))\n",
    "    linehist_l.ally, linehist_l.allx = lefty, leftx\n",
    "    linehist_r.ally, linehist_r.allx = righty, rightx\n",
    "        \n",
    "    if linehist_l.detected or linehist_r.detected:\n",
    "        # Fit a second order polynomial\n",
    "        left_fit = np.polyfit(lefty, leftx, 2) if linehist_l.detected or linehist_l.best_fit is None \\\n",
    "            else linehist_l.best_fit\n",
    "        right_fit = np.polyfit(righty, rightx, 2) if linehist_r.detected or linehist_r.best_fit is None \\\n",
    "            else linehist_r.best_fit\n",
    "        \n",
    "        # Get lane X coord at bottom and top of image\n",
    "        lane_l_x_bottom = get_lane_x_coord(left_fit, image_size[1]-1)\n",
    "        lane_l_x_top = left_fit[2]\n",
    "        lane_r_x_bottom = get_lane_x_coord(right_fit, image_size[1]-1)\n",
    "        lane_r_x_top = right_fit[2]\n",
    "        if verbose:\n",
    "            print(\"lx lane X bottom coord {}\".format(lane_l_x_bottom))\n",
    "            print(\"lx lane X top coord {}\".format(lane_l_x_top))\n",
    "            print(\"rx lane X bottom coord {}\".format(lane_r_x_bottom))\n",
    "            print(\"rx lane X top coord {}\".format(lane_r_x_top))\n",
    "    \n",
    "        # Get lane widths at bottom and top of image\n",
    "        lane_width_bottom = lane_r_x_bottom - lane_l_x_bottom\n",
    "        lane_width_top = lane_r_x_top - lane_l_x_top\n",
    "    \n",
    "        # if lane lines are detected, calculate new curvature values, otherwise, take the average\n",
    "        y_eval = image_size[1] - 1\n",
    "        if linehist_l.detected or linehist_l.best_fit is None:\n",
    "            left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "            l_curv = get_curvature(left_fit_cr, y_eval*xm_per_pix)\n",
    "        else:\n",
    "            l_curv = linehist_l.curv\n",
    "        if linehist_r.detected or linehist_r.best_fit is None:\n",
    "            right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "            r_curv = get_curvature(right_fit_cr, y_eval*xm_per_pix)\n",
    "        else:\n",
    "            r_curv = linehist_r.curv\n",
    "\n",
    "        # Check whether lane lines are approximately parallel\n",
    "        # They are reasonable parallel if the top lane width is at least <x>% of the bottom lane width\n",
    "        paral_lines_condition = np.abs(1 - lane_width_top/lane_width_bottom) >= lane_width_diff_tolerance\n",
    "        # Check whether lane curvatures are similar\n",
    "        # The curvatures are similar if the difference between the curvature is non significant\n",
    "        # w.r.t the average curvature value\n",
    "        lane_curv_condition = np.abs((l_curv - r_curv) / ((l_curv+r_curv)/2)) >= curvature_diff_tolerance\n",
    "        if verbose:\n",
    "            print(\"lane lines not enough parallel? {}\".format(paral_lines_condition))\n",
    "            print(\"relative lane width difference (top vs. bottom) {}\".format(1 - lane_width_top/lane_width_bottom))\n",
    "            print(\"curvature difference not acceptable? {}\".format(lane_curv_condition))\n",
    "            print(\"relative curvature difference {}\".format(np.abs((l_curv - r_curv) / ((l_curv+r_curv)/2))))\n",
    "\n",
    "        if linehist_l.best_fit is not None and linehist_r.best_fit is not None:\n",
    "            # 'rescuing' lane line that has consistent extremes when lines are not parallel\n",
    "            if paral_lines_condition:\n",
    "                best_fit_bottom_x_l = get_lane_x_coord(linehist_l.best_fit, image_size[1]-1)\n",
    "                best_fit_bottom_x_r = get_lane_x_coord(linehist_r.best_fit, image_size[1]-1)\n",
    "                if np.abs(1 - lane_l_x_bottom/best_fit_bottom_x_l) > lane_pos_tolerance or \\\n",
    "                   np.abs(1 - lane_l_x_top/linehist_l.best_fit[2]) > lane_pos_tolerance:\n",
    "                    linehist_l.detected = False\n",
    "                if np.abs(1 - (lane_r_x_bottom-image_size[0]/2)/(best_fit_bottom_x_r-image_size[0]/2)) > \\\n",
    "                                                                                   lane_pos_tolerance or \\\n",
    "                   np.abs(1 - (lane_r_x_top-image_size[0]/2)/(linehist_r.best_fit[2]-image_size[0]/2)) > \\\n",
    "                                                                                       lane_pos_tolerance:\n",
    "                    linehist_r.detected = False\n",
    "                \n",
    "            # 'rescuing' lane line that has consistent curvature when curvatures differ too much\n",
    "            if lane_curv_condition:\n",
    "                if np.abs(1 - l_curv/linehist_l.curv) > curvature_diff_tolerance:\n",
    "                    linehist_l.detected = False\n",
    "                if np.abs(1 - r_curv/linehist_r.curv) > curvature_diff_tolerance:\n",
    "                    linehist_r.detected = False\n",
    "            \n",
    "    # update the lane history\n",
    "    if len(linehist_l.recent_fits) >= lane_history_size:\n",
    "        linehist_l.recent_fits.popleft()\n",
    "        linehist_l.recent_curvs.popleft()\n",
    "    if linehist_l.detected or linehist_l.best_fit is None:\n",
    "        linehist_l.recent_fits.append(left_fit)\n",
    "        linehist_l.recent_curvs.append(l_curv)\n",
    "    linehist_l.best_fit = np.mean(linehist_l.recent_fits, axis=0)\n",
    "    linehist_l.curv = np.mean(linehist_l.recent_curvs)\n",
    "\n",
    "    if len(linehist_r.recent_fits) >= lane_history_size:\n",
    "        linehist_r.recent_fits.popleft()\n",
    "        linehist_r.recent_curvs.popleft()\n",
    "    if linehist_r.detected or linehist_r.best_fit is None:\n",
    "        linehist_r.recent_fits.append(right_fit)\n",
    "        linehist_r.recent_curvs.append(r_curv)\n",
    "    linehist_r.best_fit = np.mean(linehist_r.recent_fits, axis=0)\n",
    "    linehist_r.curv = np.mean(linehist_r.recent_curvs)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"left lane line detected? {}\".format(linehist_l.detected))\n",
    "        print(\"right lane line detected? {}\".format(linehist_r.detected))\n",
    "    \n",
    "    return linehist_l, linehist_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing car position and finding lanes for defined input images\n",
    "This is the section where all variables involved in the lane finding during a stream of images (a video source) are initialized.\n",
    "\n",
    "N.B.! when calculating the car curvature and position within a lane, since the values are smoothened and updated every 15 frames (0.5 seconds for a video @ 30 fps), some latency in displaying the current values is expected in the final video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "currentLine_l = Line()\n",
    "currentLine_r = Line()\n",
    "missed_lane_counter = -1\n",
    "left_fit, right_fit = np.zeros(3), np.zeros(3)\n",
    "pos_car_buffer = deque([])\n",
    "avg_curv_buffer = deque([])\n",
    "max_size_pos_car = 5\n",
    "max_size_avg_curv = 5\n",
    "update_pos_car = None\n",
    "update_avg_curv = None\n",
    "frame_count = 0\n",
    "Debug = False\n",
    "\n",
    "def get_car_position(left_fit, right_fit, xm_per_pix, image_size):\n",
    "     # Get lane X coord at bottom and top of image\n",
    "    lane_l_x_bottom = get_lane_x_coord(left_fit, image_size[1]-1)\n",
    "    lane_l_x_top = left_fit[2]\n",
    "    lane_r_x_bottom = get_lane_x_coord(right_fit, image_size[1]-1)\n",
    "    lane_r_x_top = right_fit[2]\n",
    "    \n",
    "    # Get lane widths at bottom and top of image\n",
    "    lane_width_bottom = lane_r_x_bottom - lane_l_x_bottom\n",
    "    lane_width_top = lane_r_x_top - lane_l_x_top\n",
    "    \n",
    "    # Get lane width from lane history\n",
    "    center_of_lane = lane_l_x_bottom + lane_width_bottom/2\n",
    "    return (image_size[0]/2 - center_of_lane)*xm_per_pix\n",
    "\n",
    "def find_lanes(image):\n",
    "    \n",
    "    global mtx, dist, M, Minv, currentLine_l, currentLine_r, xm_per_pix, ym_per_pix, missed_lane_counter, \\\n",
    "           left_fit, right_fit, update_pos_car, update_avg_curv, frame_count, Debug\n",
    "    \n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    ret_dict = thresholding_pipeline(undist, Debug)\n",
    "    binary_img = ret_dict[\"binary_output_tsg_sxs\"]\n",
    "    \n",
    "    result_dict = {}\n",
    "    if Debug:\n",
    "        result_dict[\"image_warped\"] = cv2.warpPerspective(image, M, binary_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "        result_dict[\"tss\"] = cv2.warpPerspective(ret_dict[\"thresh_scale_s\"], M, binary_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "        result_dict[\"tsl\"] = cv2.warpPerspective(ret_dict[\"thresh_scale_l\"], M, binary_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "        result_dict[\"tsg\"] = cv2.warpPerspective(ret_dict[\"thresh_scale_gray\"], M, binary_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "        result_dict[\"sxs\"] = cv2.warpPerspective(ret_dict[\"sobelx_s\"], M, binary_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "        result_dict[\"sxg\"] = cv2.warpPerspective(ret_dict[\"sobelx_gray\"], M, binary_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "        result_dict[\"ds\"] = cv2.warpPerspective(ret_dict[\"dir_thresh_s\"], M, binary_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    warped = cv2.warpPerspective(binary_img, M, binary_img.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    if missed_lane_counter > 2 or missed_lane_counter is -1:\n",
    "        ret_dict = find_lanes_full_search(warped, nwindows=9, margin=100, minpix=50)\n",
    "    else:\n",
    "        ret_dict = find_lane_quick_search(warped, left_fit, right_fit, margin=100)\n",
    "\n",
    "    currentLine_l, currentLine_r = sanity_check(currentLine_l, currentLine_r, ret_dict[\"lefty\"], ret_dict[\"leftx\"], \\\n",
    "                                                ret_dict[\"righty\"], ret_dict[\"rightx\"], \\\n",
    "                                                xm_per_pix, ym_per_pix, binary_img.shape[::-1], verbose=False)\n",
    "    \n",
    "    if not currentLine_l.detected or not currentLine_r.detected:\n",
    "        missed_lane_counter += 1\n",
    "    else:\n",
    "        missed_lane_counter = 0\n",
    "    \n",
    "    lefty, leftx, righty, rightx = currentLine_l.ally, currentLine_l.allx, \\\n",
    "                                   currentLine_r.ally, currentLine_r.allx\n",
    "    left_fit, right_fit, l_curv, r_curv = currentLine_l.best_fit, currentLine_r.best_fit, \\\n",
    "                                          currentLine_l.curv, currentLine_r.curv\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(image).astype(np.uint8)\n",
    "        \n",
    "    # Color points detected in each lane rectangular search area\n",
    "    if currentLine_l.detected:\n",
    "        color_warp[lefty, leftx] = [255, 0, 0]\n",
    "    if currentLine_r.detected:\n",
    "        color_warp[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    # Further smoothing of car position w.r.t. center of lane and curvature of lane values\n",
    "    pos_car_buffer.append(get_car_position(left_fit, right_fit, xm_per_pix, binary_img.shape[::-1]))\n",
    "    avg_curv_buffer.append((l_curv+r_curv)/2)\n",
    "    if len(pos_car_buffer) > max_size_pos_car:\n",
    "        pos_car_buffer.popleft()\n",
    "    if len(avg_curv_buffer) > max_size_avg_curv:\n",
    "        avg_curv_buffer.popleft()\n",
    "    \n",
    "    # Update text superimposed on frame\n",
    "    if frame_count % 15 is 0:\n",
    "        update_pos_car = np.mean(pos_car_buffer)\n",
    "        update_avg_curv = np.mean(avg_curv_buffer)\n",
    "    cv2.putText(result,\"Car X pos. {0:.2f} m\".format(update_pos_car), (100,50), \\\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, [255, 255, 255], thickness=2)\n",
    "    cv2.putText(result,\"Road curv. {0:.0f} m\".format(update_avg_curv), (100,80), \\\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, [255, 255, 255], thickness=2)\n",
    "    frame_count += 1\n",
    "    \n",
    "    if Debug:\n",
    "        result_dict[\"out_image\"] = result\n",
    "        return result_dict\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processing each frame of a given video and write output frames with lane highlighted or step through some frames of the video for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "video_output_file = 'project_video_out.mp4'\n",
    "video_input = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "# For debugging purposes, some stages of the thresholding pipeline can be outputted while\n",
    "# running the lane finding on the video frames\n",
    "if not Debug:\n",
    "    video_output = video_input.fl_image(find_lanes)\n",
    "    %time video_output.write_videofile(video_output_file, audio=False)\n",
    "else:\n",
    "    for t in np.linspace(0, 2, 30)[0:4]:\n",
    "        image = video_input.get_frame(t)\n",
    "        print('\\ntime {}'.format(t))\n",
    "        ret_dict = find_lanes(image)\n",
    "#        plt.figure(figsize=(15,15))\n",
    "#        plt.imshow(ret_dict[\"tss\"])\n",
    "#        plt.figure(figsize=(15,15))\n",
    "#        plt.imshow(ret_dict[\"tsl\"])\n",
    "#        plt.figure(figsize=(15,15))\n",
    "#        plt.imshow(ret_dict[\"tsg\"])\n",
    "#        plt.figure(figsize=(15,15))\n",
    "#        plt.imshow(ret_dict[\"sxs\"])\n",
    "#        plt.figure(figsize=(15,15))\n",
    "#        plt.imshow(ret_dict[\"sxg\"])\n",
    "#        plt.figure(figsize=(15,15))\n",
    "#        plt.imshow(ret_dict[\"image_warped\"])\n",
    "#        plt.figure(figsize=(15,15))\n",
    "#        plt.imshow(ret_dict[\"ds\"])\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(ret_dict[\"out_image\"])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
